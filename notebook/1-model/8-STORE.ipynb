{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py 模型训练阶段\n",
    "\n",
    "model = MyModel()\n",
    "# 实例化Checkpoint，指定保存对象为model（如果需要保存Optimizer的参数也可加入）\n",
    "checkpoint = tf.train.Checkpoint(myModel=model)\n",
    "# ...（模型训练代码）\n",
    "# 模型训练完毕后将参数保存到文件（也可以在模型训练过程中每隔一段时间就保存一次）\n",
    "checkpoint.save('./save/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py 模型使用阶段\n",
    "\n",
    "model = MyModel()\n",
    "checkpoint = tf.train.Checkpoint(myModel=model)             # 实例化Checkpoint，指定恢复对象为model\n",
    "checkpoint.restore(tf.train.latest_checkpoint('./save'))    # 从文件恢复模型参数\n",
    "# 模型使用代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例，以  多层感知机模型 为例展示模型变量的保存和载入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "from zh.model.mnist.mlp import MLP\n",
    "from zh.model.utils import MNISTLoader\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('--mode', default='train', help='train or test')\n",
    "parser.add_argument('--num_epochs', default=1)\n",
    "parser.add_argument('--batch_size', default=50)\n",
    "parser.add_argument('--learning_rate', default=0.001)\n",
    "args = parser.parse_args()\n",
    "data_loader = MNISTLoader()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model = MLP()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate)\n",
    "    num_batches = int(data_loader.num_train_data // args.batch_size * args.num_epochs)\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model)      # 实例化Checkpoint，设置保存对象为model\n",
    "    for batch_index in range(1, num_batches+1):                 \n",
    "        X, y = data_loader.get_batch(args.batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        if batch_index % 100 == 0:                              # 每隔100个Batch保存一次\n",
    "            path = checkpoint.save('./save/model.ckpt')         # 保存模型参数到文件\n",
    "            print(\"model saved to %s\" % path)\n",
    "\n",
    "\n",
    "def test():\n",
    "    model_to_be_restored = MLP()\n",
    "    # 实例化Checkpoint，设置恢复对象为新建立的模型model_to_be_restored\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model_to_be_restored)      \n",
    "    checkpoint.restore(tf.train.latest_checkpoint('./save'))    # 从文件恢复模型参数\n",
    "    y_pred = np.argmax(model_to_be_restored.predict(data_loader.test_data), axis=-1)\n",
    "    print(\"test accuracy: %f\" % (sum(y_pred == data_loader.test_label) / data_loader.num_test_data))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if args.mode == 'train':\n",
    "        train()\n",
    "    if args.mode == 'test':\n",
    "        test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下提供一个实例，展示使用 CheckpointManager 限制仅保留最后三个 Checkpoint 文件，并使用 batch 的编号作为 Checkpoint 的文件编号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "from zh.model.mnist.mlp import MLP\n",
    "from zh.model.utils import MNISTLoader\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('--mode', default='train', help='train or test')\n",
    "parser.add_argument('--num_epochs', default=1)\n",
    "parser.add_argument('--batch_size', default=50)\n",
    "parser.add_argument('--learning_rate', default=0.001)\n",
    "args = parser.parse_args()\n",
    "data_loader = MNISTLoader()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model = MLP()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate)\n",
    "    num_batches = int(data_loader.num_train_data // args.batch_size * args.num_epochs)\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model)      \n",
    "    # 使用tf.train.CheckpointManager管理Checkpoint\n",
    "    manager = tf.train.CheckpointManager(checkpoint, directory='./save', max_to_keep=3)\n",
    "    for batch_index in range(1, num_batches):\n",
    "        X, y = data_loader.get_batch(args.batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        if batch_index % 100 == 0:\n",
    "            # 使用CheckpointManager保存模型参数到文件并自定义编号\n",
    "            path = manager.save(checkpoint_number=batch_index)         \n",
    "            print(\"model saved to %s\" % path)\n",
    "\n",
    "\n",
    "def test():\n",
    "    model_to_be_restored = MLP()\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model_to_be_restored)      \n",
    "    checkpoint.restore(tf.train.latest_checkpoint('./save'))\n",
    "    y_pred = np.argmax(model_to_be_restored.predict(data_loader.test_data), axis=-1)\n",
    "    print(\"test accuracy: %f\" % (sum(y_pred == data_loader.test_label) / data_loader.num_test_data))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if args.mode == 'train':\n",
    "        train()\n",
    "    if args.mode == 'test':\n",
    "        test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
